---
title: "MATH 216 Homework 2 Revision"
author: "Shaojin Li"
output: html_document
---

```{r, echo=FALSE, message=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(foreign))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(pander))
```


## Admistrative:

Please indicate

* Who you collaborated with: None
* Roughly how much time you spent on this HW: 10hrs+3.5hrs (revision)
* What gave you the most trouble: 
* Any comments you have: 

## Question 1:

Question 4 on page 76 from Chapter 4 of Data Analysis Using Regression and
Multilevel/Hierarchical Models.  The codebook can be found
[here](http://www.stat.columbia.edu/~gelman/arm/examples/pollution/pollution.txt).
I've included R code blocks for each question, but use them only if you feel it
necessary.

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
url <- "http://www.stat.columbia.edu/~gelman/arm/examples/pollution/pollution.dta"
pollution <- read.dta(url) %>% 
  tbl_df()
```

### a)

```{r, echo=FALSE, fig.width=12, fig.height=6}
#(a) Create a scatterplot of mortality rate versus level of nitric oxides. 
#Do you think linear regression will fit these data well? 
#Fit the regression and evaluate a residual plot from the regression.

#Scatterplot
plot1a1<-ggplot(data=pollution, aes(x=nox, y=mort))+ 
  geom_point()+
  ggtitle("Mortaility Rate vs.Nitric Oxides")+
  xlab("Relative Nitric Oxides Pollution Potential")+
  ylab("Total Age-adjusted Mortality Rate per 100,000")
plot1a1

#Fit regression line
plot1a1<-plot1a1+
  geom_smooth(method="lm")
plot1a1

#Regression & get residuals 
model1a<-lm(mort~nox, data=pollution)
kable(summary(model1a)$coef, digits=3)

#Plot redisuals
resid_1a<-resid(model1a)

plot1a2<-ggplot(data=pollution, aes(x=nox, y=resid_1a))+
  geom_point()+
  ggtitle("Residuals vs.Nitric Oxides")+
  xlab("Relative Nitric Oxides Pollution Potential")+
  ylab("Residuals")+
  geom_hline(yintercept=0, color="blue")
plot1a2

```

I do not think linear regression will fit these data well because the scatterplot does not show a linear relationship of the two variables. Looking at the resituals graph we can see that although residuals are centered around zero, they are not randomly dispersed as they heavely skewed within the 0-50 range. 

### b)

```{r, echo=FALSE, fig.width=12, fig.height=6}
#(b) Find an appropriate transformation that will result in data more #appropriate for linear regression. 
#Fit a regression to the transformed data and evaluate the new residual plot.

#Log plot
pollution<-mutate(pollution, log_nox=log(nox)) 

plot1b1<-ggplot(data=pollution, aes(x=log_nox, y=mort))+ 
  geom_point()+
  ggtitle("Mortaility Rate vs.Log of Nitric Oxides")+
  xlab("Log of Relative Nitric Oxides Pollution Potential")+
  ylab("Total Age-adjusted Mortality Rate per 100,000")+
  geom_smooth(method="lm")
plot1b1

#Log regression & get residuals 
model1b<-lm(mort~log_nox, data=pollution)
model1b

resid_1b<-resid(model1b)

#Plot residuals
plot1b2<-ggplot(data=pollution, aes(x=log_nox, y=resid_1b))+
  geom_point()+
  ggtitle("Residuals vs.Log of Nitric Oxides")+
  xlab("Log of Relative Nitric Oxides Pollution Potential")+
  ylab("Residuals")+
  geom_hline(yintercept=0, color="blue")
plot1b2

```

As demonstrated in the scatterplot, a log transformation will result in data more appropriate for linear regression as it better represents the correlationship between nitric oxides and mortality rate. The residuals plot proves that under a log transformation, the residuals are more randomly dispersed while still centered around zero.

### c)

```{r, echo=FALSE, fig.width=12, fig.height=6}
#(c) Interpret the slope coefficient from the model you chose in (b).

coefficients(model1b)
kable(confint(model1b), digits=3)

```

The slope coefficient from the log model predicts that for 1 percent increase in nitric oxides pollution potential, there is a 15.3 increase in the total age-adjusted mortality rate per 100,000. The confidence interval is [2.133, 28.538], which means that we are 95% confident that the increase of mortality rate per 100,000 due to 1 percent increase in nitric oxides will be between 2.133 and 28.538. 

### d) 

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Now fit a model predicting mortality rate using levels of nitric oxides, 
#sulfur dioxide, and hydrocarbons as inputs. Use appropriate transformations 
#when helpful. Plot the fitted regression model and interpret the coefficients.

#Make scatterplots to find the correlationship
ggplot(data=pollution, aes(x=so2, y=mort))+ 
  geom_jitter()
ggplot(data=pollution, aes(x=hc, y=mort))+ 
  geom_jitter()
  #The plots of sulfur dioxide and hydrocarbons look pretty similar to the
  #pattern of nitric oxides, so I decided to apply log transformations on these
  #variables as well.

#Plot regression model
pollution<-mutate(pollution, log_so2=log(so2)) %>%
  mutate (log_hc=log(hc))

#Plot regression model of HC
plot1d1<-ggplot(data=pollution, aes(x=log_hc, y=mort))+ 
  geom_point()+
  ggtitle("Mortaility Rate vs.Log of Hydrocarbons")+
  xlab("Log of Relative Hydrocarbons Pollution Potential")+
  ylab("Total Age-adjusted Mortality Rate per 100,000")+
  geom_smooth(method="lm")
plot1d1

#Plot regression model of SO2
plot1d2<-ggplot(data=pollution, aes(x=log_so2, y=mort))+ 
  geom_point()+
  ggtitle("Mortaility Rate vs.Log of Sulfur Dioxide")+
  xlab("Log of Relative Sulfur Dioxide Pollution Potential")+
  ylab("Total Age-adjusted Mortality Rate per 100,000")+
  geom_smooth(method="lm")
plot1d2

#Get regression table
model1d<-lm(mort~log_nox + log_so2 + log_hc, data=pollution)

#The "pander" command does not work in the KnitHTML output so I switched to "kable"
kable(summary(model1d)$coef, digits=3)

kable(confint(model1d), digits=3)
```

The slope coefficient from the log model predicts that for 1 percent increase in the pollution potential of nitric oxides, sulfur dioxide, and hydrocarbons, there is respectively a 58.3 increase, 11.8 increase, and 57.3 decrease in the total age-adjusted mortality rate per 100,000. The confidence interval of nitric oxides, sulfur dioxide, and hydrocarbons is [14.8, 101.9], [-2.6, 26.1], and [-96.2, -18.4] respectively, which means that sulfur dioxide does not have a significant relationship with mortality because its confidence interval contains zero.

### e)

```{r, echo=FALSE, fig.width=12, fig.height=6}
#(e) Cross-validate: fit the model you chose above to the first half of the data
#and then predict for the second half. 
#(You used all the data to construct the model in (d), so this is not really
#cross-validation, but it gives a sense of how the steps of cross-validation can
#be implemented.)

#Generate a random half of the sample and the rest of the sample
samp1<-pollution[sample(nrow(pollution), 30), ] 
samp2<-anti_join(pollution, samp1, by="mort")

model1e<-lm(mort~log_nox + log_so2 + log_hc, data=samp1)
prediction<-predict(model1e, data=samp2)

#Plot prediction of the second half versus the actual value
plot1e<-ggplot(data=samp2, aes(x=prediction, y=mort))+ 
  geom_point()+
  geom_abline(intercept=0, slope=1)+
  ggtitle("Fitted vs.True Value of Pollution Data")+
  xlab("Prediction")+
  ylab("True Value")
plot1e

```

From the plot we can see that only a few of the spots are on the y=x line (where fitted value equals to true value), which means that the model is onoly a rough estimation of the value of the pollution data.

### f) What do you think are the reasons for using cross-validation?

```{r, echo=FALSE, fig.width=12, fig.height=6}

```
Cross-validation helps us to know whether the resulting model generalizes well to other data sets than the one observed. It helps us to know whether we can apply our model to other data sets and be confident of the predicted results. 

## Question 2:

Perform an Exploratory Data Analysis (EDA) of the OkCupid data, keeping in mind 
in HW-3, you will be fitting a logistic regression to predict gender. What do I mean by EDA?

* Visualizations
* Tables
* Numerical summaries

For the R Markdown to work, you must first copy the file `profiles.csv` from
Lec09 to the project directory `HW-2`.

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("profiles.csv", header=TRUE) %>% tbl_df()

```

What is our sample? Look at demographic information
```{r, echo=FALSE, fig.width=12, fig.height=6}
#From Lec9
#Split off the essays into a separate data.frame
essays<-select(profiles, contains("essay"))
profiles<-select(profiles, -contains("essay"))
#Define a binary outcome variable
profiles<-mutate(profiles, is_female = ifelse(sex=="f", 1, 0))

#We are intereted in gender info in order to fit a logistic regression to #predict gender in HW3
mean(profiles$is_female)
  #Only 40.2% female

#Delete variables whose gender information is missing
profiles<-filter(profiles, sex!="")

#Age info
age<-ggplot(data=profiles) +
  geom_histogram(aes(x=age, y=..density..)) +
  facet_wrap(~sex, ncol=1) +
  ggtitle("Age")
age

#Heights info
heights<-ggplot(data=profiles, aes(x=height, y=is_female)) +
  geom_jitter() +
  ggtitle("Height vs. Gender")+
  ylab("Female?")+
  xlab("Height")
heights

#We can see from the graph that some people report their heights to be less than 27 inches, which is unreasonable. So we replace those with a N/A in the data in order to avoid outliers in the next step.
profiles$height[profiles$height<27] <- NA

#Age, height, income stats table
#Numeric variables
demo<-profiles %>% 
  group_by(sex) %>% 
  summarise (age_mean=mean(age, na.rm=TRUE), 
          age_sd=sd(age), 
          height_mean=mean(height, na.rm=TRUE), 
          height_sd=sd(height, na.rm=TRUE),  
          income_mean=mean(ifelse(income>=0, income,NA),na.rm=TRUE),
          income_sd=sd(ifelse(income>=0, income,NA),na.rm=TRUE)) 

kable(demo, digits=2)

```

This sample consists of only 40.2% female. By looking at the age plot and the height plot, we can see that male is on average taller than female, but cannot see a huge difference in terms of age. From the statistics table we can see that in our sample, male is on average taller than female and has higher income. Male is on average younger than female by 0.8 year and has a smaller standard deviation.

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Gender stats
sex<-profiles %>%
  group_by(sex) %>%
  tally() %>%
  rename(total_sex=n)

#Status info by sex
status_sex<-profiles %>%
  group_by(sex, status) %>% 
  tally() %>%
  rename (n_people=n) 

prop_sex <-inner_join (status_sex, sex, by="sex") %>%
  mutate (percent_status=100*n_people/total_sex) 

plot_status_sex<-ggplot(prop_sex, aes(x=sex, y=percent_status, fill=status))+
  geom_bar(stat="identity")+
  xlab("Gender") + 
  ylab("Proportion of People") +
  ggtitle("Status vs. Sex")
plot_status_sex

kable(prop_sex, digits=2)

#Orientation info
ori_sex<-profiles %>%
  group_by(sex, orientation) %>% 
  tally() %>%
  rename (n_people=n)

prop_ori<-inner_join (ori_sex, sex, by="sex") %>%
  mutate (percent_ori=100*n_people/total_sex) 

plot_ori_sex<-ggplot(prop_ori, aes(x=sex, y=percent_ori, fill=orientation))+
  geom_bar(stat="identity")+
  xlab("Gender") + 
  ylab("Proportion of People") +
  ggtitle("Orientation vs. Sex")
plot_ori_sex

```

The status table shows us that in our sample, the proportions of single male and single female are similar. In the table, the percent_status column shows the percentage of a certain status of that gender, which means that all the statuses for a given sex sum up to 100%, instead of the whole column.From the status plot we can see that female and male have a similar proportion of people who are single, available, or seeing someone.

The orientation plot shows that there are proportionally more gay male than female, while both male and female have a similar proportion of straight people.


